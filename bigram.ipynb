{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62b5ff77",
   "metadata": {},
   "source": [
    "# <u> Dataset Creation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf88bad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_character_dialogues(character,file):\n",
    "    dialogues = []\n",
    "    with open(file) as f:\n",
    "        for line in f:\n",
    "            search_line = line.lower()\n",
    "            anya_found = search_line.find(character)\n",
    "            comma_found = search_line.find(',,')\n",
    "            if anya_found != -1 and comma_found != -1 and anya_found < comma_found:\n",
    "                dialogues.append(line[comma_found+2:])\n",
    "    return dialogues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a60932d2",
   "metadata": {},
   "source": [
    "## after uploading all .ass files and folders to the current working directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e521ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76807faa",
   "metadata": {},
   "outputs": [],
   "source": [
    "bracket_content = re.compile(r'\\{.*?\\}|shock!|\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8676eec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = Path('.')\n",
    "paths = list(p.glob('**/*.eng.ass'))\n",
    "character = 'anya'\n",
    "dialogues = []\n",
    "for path in paths:\n",
    "    dialogues.extend(retrieve_character_dialogues(character,path))\n",
    "cleaned_dialogues = bracket_content.sub(\"\",\"\".join(dialogues))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e87d9",
   "metadata": {},
   "source": [
    "## Preliminary Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48b0d500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory size: 101 KB\n",
      "Number of dialogues: 51963\n",
      "Vocabulary size: 69\n",
      "Possible Vocabulary = [ !\"'(),-.012578:?ABCDEFGHIJKLMNOPRSTUVWYZ\\abcdefghijklmnopqrstuvwxyz—]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "size_kb = sys.getsizeof(cleaned_dialogues) // 1024\n",
    "print(f\"Memory size: {size_kb} KB\")\n",
    "\n",
    "print(f\"Number of dialogues: {len(cleaned_dialogues)}\")\n",
    "\n",
    "chars = sorted(set(cleaned_dialogues))\n",
    "vocab_size = len(chars)\n",
    "print(f\"Vocabulary size: {vocab_size}\")\n",
    "print(f\"Possible Vocabulary = [{''.join(chars)}]\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f160f5a",
   "metadata": {},
   "source": [
    "> ### <u> NOTE: </u>\n",
    ">\n",
    "> - <b>The amount of data is quite low but we dont really care about overfitting for this model right now, although the we still  should have around an MB of \n",
    "> data if possible\n",
    ">   \n",
    ">\n",
    "> <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970f8473",
   "metadata": {},
   "source": [
    "## Encoder and Decoder Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "881e37b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : ''.join(itos[i] for i in l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "487dbad6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoded text :  [24, 46, 49, 46]\n",
      "decoded text : Hehe\n"
     ]
    }
   ],
   "source": [
    "encoded_text = encode(\"Hehe\")\n",
    "print('encoded text : ', encoded_text)\n",
    "decoded_text = decode(encoded_text)\n",
    "print('decoded text :',decoded_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb26a352",
   "metadata": {},
   "source": [
    "## Storing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7c4363b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([51963]) torch.int64\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "data = torch.tensor(encode(cleaned_dialogues),dtype=torch.long)\n",
    "print(data.shape, data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270c8598",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3fe35a",
   "metadata": {},
   "source": [
    "## Splitting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97c1e3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = int(0.8*len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data [n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b270d5ba",
   "metadata": {},
   "source": [
    "## visualizing one training example "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "47d20f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "given context tensor([25]) the next predicted token should be 0\n",
      "given context tensor([25,  0]) the next predicted token should be 42\n",
      "given context tensor([25,  0, 42]) the next predicted token should be 54\n",
      "given context tensor([25,  0, 42, 54]) the next predicted token should be 0\n",
      "given context tensor([25,  0, 42, 54,  0]) the next predicted token should be 17\n",
      "given context tensor([25,  0, 42, 54,  0, 17]) the next predicted token should be 55\n",
      "given context tensor([25,  0, 42, 54,  0, 17, 55]) the next predicted token should be 66\n",
      "given context tensor([25,  0, 42, 54,  0, 17, 55, 66]) the next predicted token should be 42\n"
     ]
    }
   ],
   "source": [
    "blocksize = 8 \n",
    "x = train_data[:blocksize]\n",
    "y = train_data[1:blocksize+1]\n",
    "for t in range(blocksize):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f'given context {context} the next predicted token should be {target}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd11ee51",
   "metadata": {},
   "source": [
    "a sequence of n characters typically has n-1 training examples, we take (n+1) characters  to match the 'block_size' or number of training examples per sequence. eg: for block_size 8 we would consider a sequence of 9 characters so we get 8 training examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7fb359f",
   "metadata": {},
   "source": [
    "## Creating Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "696a598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting seed for consistent output\n",
    "torch.manual_seed(74)\n",
    "batch_size = 4 \n",
    "block_size = 8 \n",
    "# gets 4 sequences of 8 characters\n",
    "def get_batch(split):\n",
    "    data = train_data if split == 'train' else val_data\n",
    "    ix = torch.randint(len(data) - block_size,(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1 : i+block_size+1] for i in ix])\n",
    "    return x,y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7d29cf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs (xb):\n",
      "  Shape: torch.Size([4, 8]), \n",
      " Values: tensor([[43, 46, 60, 61,  8, 30, 56, 64],\n",
      "        [ 0, 17, 55, 66, 42,  0, 44, 42],\n",
      "        [25,  0, 64, 42, 55, 61,  0, 61],\n",
      "        [63, 46, 60,  1,  0, 23, 50, 63]])\n",
      "\n",
      "Targets (yb):\n",
      "  Shape: torch.Size([4, 8]), \n",
      " Values: tensor([[46, 60, 61,  8, 30, 56, 64,  0],\n",
      "        [17, 55, 66, 42,  0, 44, 42, 55],\n",
      "        [ 0, 64, 42, 55, 61,  0, 61, 56],\n",
      "        [46, 60,  1,  0, 23, 50, 63, 46]])\n"
     ]
    }
   ],
   "source": [
    "xb, yb = get_batch('train')\n",
    "\n",
    "print(\"Inputs (xb):\")\n",
    "print(f\"  Shape: {xb.shape}, \\n Values: {xb}\")\n",
    "print(\"\\nTargets (yb):\")\n",
    "print(f\"  Shape: {yb.shape}, \\n Values: {yb}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f68a5b33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch: 0, Time Step: 1\n",
      "Context: tensor([43])\n",
      "Target: 46\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 2\n",
      "Context: tensor([43, 46])\n",
      "Target: 60\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 3\n",
      "Context: tensor([43, 46, 60])\n",
      "Target: 61\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 4\n",
      "Context: tensor([43, 46, 60, 61])\n",
      "Target: 8\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 5\n",
      "Context: tensor([43, 46, 60, 61,  8])\n",
      "Target: 30\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 6\n",
      "Context: tensor([43, 46, 60, 61,  8, 30])\n",
      "Target: 56\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 7\n",
      "Context: tensor([43, 46, 60, 61,  8, 30, 56])\n",
      "Target: 64\n",
      "________________________________________\n",
      "Batch: 0, Time Step: 8\n",
      "Context: tensor([43, 46, 60, 61,  8, 30, 56, 64])\n",
      "Target: 0\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 1\n",
      "Context: tensor([0])\n",
      "Target: 17\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 2\n",
      "Context: tensor([ 0, 17])\n",
      "Target: 55\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 3\n",
      "Context: tensor([ 0, 17, 55])\n",
      "Target: 66\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 4\n",
      "Context: tensor([ 0, 17, 55, 66])\n",
      "Target: 42\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 5\n",
      "Context: tensor([ 0, 17, 55, 66, 42])\n",
      "Target: 0\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 6\n",
      "Context: tensor([ 0, 17, 55, 66, 42,  0])\n",
      "Target: 44\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 7\n",
      "Context: tensor([ 0, 17, 55, 66, 42,  0, 44])\n",
      "Target: 42\n",
      "________________________________________\n",
      "Batch: 1, Time Step: 8\n",
      "Context: tensor([ 0, 17, 55, 66, 42,  0, 44, 42])\n",
      "Target: 55\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 1\n",
      "Context: tensor([25])\n",
      "Target: 0\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 2\n",
      "Context: tensor([25,  0])\n",
      "Target: 64\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 3\n",
      "Context: tensor([25,  0, 64])\n",
      "Target: 42\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 4\n",
      "Context: tensor([25,  0, 64, 42])\n",
      "Target: 55\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 5\n",
      "Context: tensor([25,  0, 64, 42, 55])\n",
      "Target: 61\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 6\n",
      "Context: tensor([25,  0, 64, 42, 55, 61])\n",
      "Target: 0\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 7\n",
      "Context: tensor([25,  0, 64, 42, 55, 61,  0])\n",
      "Target: 61\n",
      "________________________________________\n",
      "Batch: 2, Time Step: 8\n",
      "Context: tensor([25,  0, 64, 42, 55, 61,  0, 61])\n",
      "Target: 56\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 1\n",
      "Context: tensor([63])\n",
      "Target: 46\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 2\n",
      "Context: tensor([63, 46])\n",
      "Target: 60\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 3\n",
      "Context: tensor([63, 46, 60])\n",
      "Target: 1\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 4\n",
      "Context: tensor([63, 46, 60,  1])\n",
      "Target: 0\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 5\n",
      "Context: tensor([63, 46, 60,  1,  0])\n",
      "Target: 23\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 6\n",
      "Context: tensor([63, 46, 60,  1,  0, 23])\n",
      "Target: 50\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 7\n",
      "Context: tensor([63, 46, 60,  1,  0, 23, 50])\n",
      "Target: 63\n",
      "________________________________________\n",
      "Batch: 3, Time Step: 8\n",
      "Context: tensor([63, 46, 60,  1,  0, 23, 50, 63])\n",
      "Target: 46\n",
      "________________________________________\n"
     ]
    }
   ],
   "source": [
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]   # Show context slice up to t+1\n",
    "        target = yb[b, t]       # Show current target\n",
    "        print(f\"Batch: {b}, Time Step: {t+1}\")\n",
    "        print(f\"Context: {context}\")\n",
    "        print(f\"Target: {target}\")\n",
    "        print(\"_\" * 40)         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83814163",
   "metadata": {},
   "source": [
    "# SIMPLEST BASELINE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbddd9a",
   "metadata": {},
   "source": [
    "## Defining the Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6950e6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.6637, grad_fn=<NllLossBackward0>)\n",
      " t,Oi!2eAo D2)igt!R:K7OJiutoNybkO:—?Ob0Pv7aTVx\"a)OluxG.kK—ojDLKe7H!E oa-fgLn0BA)mhN:KmFLvL2Fo0PrmEdLD\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "from torch.nn import functional as F\n",
    "\n",
    "torch.manual_seed(74)\n",
    "#TL:DR each row maps to a character and gives logits or it, i.e next character predictions given an input characters idx\n",
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self,vocab_size):\n",
    "        super().__init__()\n",
    "        # the trainable params here are just weights of size vocab_size * vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size,vocab_size)\n",
    "    \n",
    "    def forward(self, idx, targets=None):\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            logits = rearrange(logits, 'b t c -> (b t) c')\n",
    "            targets = rearrange(targets, 'b t -> (b t)' )\n",
    "            loss = F.cross_entropy(logits,targets)\n",
    "        \n",
    "        return logits,loss\n",
    "    def generate(self,idx, max_new_tokens):\n",
    "        for _ in range(max_new_tokens):\n",
    "            logits,loss = self(idx)\n",
    "\n",
    "            logits = logits[:, -1 , :]\n",
    "            \n",
    "            probs = F.softmax(logits,dim=-1)\n",
    "            idx_next =torch.multinomial(probs,num_samples=1)\n",
    "            idx = torch.cat((idx,idx_next),dim=1)\n",
    "        return idx\n",
    "m = BigramLanguageModel(vocab_size)\n",
    "logits,loss = m(xb,yb)\n",
    "print(loss)\n",
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype=torch.long), max_new_tokens=100)[0].tolist()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a586c6d",
   "metadata": {},
   "source": [
    "> **Note**  \n",
    "> Even though we pass the entire sequence of logits into the next forward pass, this is still a **bigram model** — it only uses the **immediately previous character** to predict the next one.  \n",
    ">  \n",
    "> The reason we concatenate the entire sequence and then take only the last prediction is for **consistency**. The same forward function can then be reused for more complex models (like Transformers), where the full sequence context actually matters.\n",
    ">\n",
    "> also to use the model on gpu both the data and the parameters need to be offloaded to the gpu to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd357cfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(m.parameters(), lr = 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2d6cd22f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss :  2.4704837799072266\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "for step in range(10000):\n",
    "    \n",
    "    xb,yb = get_batch('train')\n",
    "    \n",
    "    logits , loss = m(xb,yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "print(\"loss : \",loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "885e8836",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " wa, buss t's!Gis g gorrdicomeven't tes!Shoocuy's..\n"
     ]
    }
   ],
   "source": [
    "print(decode(m.generate(idx = torch.zeros((1,1),dtype=torch.long), max_new_tokens=50)[0].tolist()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers-from-scratch (3.12.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
